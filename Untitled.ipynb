{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import scipy\n",
    "import statsmodels\n",
    "from fbprophet import Prophet\n",
    "\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 446.40 MB\n",
      "Memory usage after optimization is: 95.42 MB\n",
      "Decreased by 78.6%\n",
      "Memory usage of dataframe is 208.77 MB\n",
      "Memory usage after optimization is: 45.77 MB\n",
      "Decreased by 78.1%\n",
      "Memory usage of dataframe is 13.49 MB\n",
      "Memory usage after optimization is: 4.83 MB\n",
      "Decreased by 64.2%\n",
      "Memory usage of dataframe is 0.21 MB\n",
      "Memory usage after optimization is: 0.22 MB\n",
      "Decreased by -5.7%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calendar_data = pd.read_csv('calendar.csv')\n",
    "price_data = pd.read_csv('sell_prices.csv')\n",
    "submission_data = pd.read_csv('sample_submission.csv')\n",
    "sales_train = pd.read_csv('sales_train_validation.csv')\n",
    "evaluation_data = pd.read_csv('sales_train_evaluation.csv')\n",
    "\n",
    "sales_data = reduce_mem_usage(sales_data)\n",
    "price_data = reduce_mem_usage(price_data)\n",
    "submission_data = reduce_mem_usage(submission_data)\n",
    "calendar_data = reduce_mem_usage(calendar_data)\n",
    "\n",
    "d_cols = [c for c in sales_data.columns if 'd_' in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(sales_train.shape[0])):\n",
    "    #print('We are at product {} out of {}'.format(i,sales_train.shape[0]))\n",
    "    temp_series = sales_train.iloc[i,600:]\n",
    "    temp_series.index = calendar_df['date'][600:600+len(temp_series)]\n",
    "    temp_series =  pd.DataFrame(temp_series)\n",
    "    temp_series = temp_series.reset_index()\n",
    "    temp_series.columns = ['ds', 'y']\n",
    "\n",
    "    m1 = Prophet(uncertainty_samples=False)\n",
    "    m1.fit(temp_series)\n",
    "\n",
    "    future1 = m1.make_future_dataframe(periods=28).tail(28)\n",
    "    forecast1 = m1.predict(future1)\n",
    "\n",
    "    submission.iloc[i,1:] = forecast1['yhat'].iloc[-28:].values\n",
    "    submission.iloc[:,1:][submission.iloc[:,1:]<0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val():\n",
    "    start_day = min(calendar_data['date'])\n",
    "    start_day = datetime.datetime.strptime('2011-01-29','%Y-%m-%d').date()\n",
    "    dates = [start_day + i*datetime.timedelta(days =1) for i in range(0,len(d_cols))]\n",
    "    train_start = 0\n",
    "    train_end = dates[-29]\n",
    "    return train_end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_snapshot(calendar_data,sales_data,id_lst):\n",
    "    #from datetime import strptime\n",
    "    start_day = datetime.datetime.strptime(min(calendar_data['date']),'%Y-%m-%d').date()\n",
    "    dates = [start_day + i*datetime.timedelta(days =1) for i in range(0,len(d_cols))]\n",
    "    gs_temp = pd.DataFrame()\n",
    "    gs_snapshot = pd.DataFrame()\n",
    "    for item in id_lst:\n",
    "        gs_temp['snapshot_date'] = dates\n",
    "        gs_temp['id'] = item\n",
    "        gs_temp['cat_id']  = sales_data.loc[sales_data['id']==item]['cat_id'].values[0]\n",
    "        gs_temp['store_id']  = sales_data.loc[sales_data['id']==item]['store_id'].values[0]\n",
    "        gs_temp['state_id'] = sales_data.loc[sales_data['id']==item]['state_id'].values[0]\n",
    "        gs_temp['item_id'] = sales_data.loc[sales_data['id']==item]['item_id'].values[0]\n",
    "        gs_temp['sales'] = sales_data.loc[sales_data['id']==item][d_cols].T.values\n",
    "        gs_snapshot = pd.concat([gs_snapshot,gs_temp])\n",
    "    return gs_snapshot\n",
    "\n",
    "def convert_to_wm_yr_wk(df):\n",
    "    df['wm_yr_wk'] = df['snapshot_date'].apply(lambda x:str(x.isocalendar()[0])[-2:]+ \n",
    "                                               (str(x.isocalendar()[1]) if x.isocalendar()[1]>10 \n",
    "                                         else '0'+ str(x.isocalendar()[1]))+str(x.isocalendar()[1]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_count()-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_price_cal_data(price_data,calendar_data):\n",
    "    price_cal = price_data.merge(calendar_data, on = ['wm_yr_wk'], how = 'left')\n",
    "    price_cal.rename({'date':'snapshot_date'},\n",
    "                 inplace = True, axis =1)\n",
    "    price_cal.drop(['wm_yr_wk','weekday','month','year'],axis = 1, inplace = True)\n",
    "    price_cal['snapshot_date'] = price_cal['snapshot_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').date())\n",
    "\n",
    "    #price_cal.head()\n",
    "    return price_cal\n",
    "\n",
    "def merge_snapshot_pricecal(price_cal, gs_snapshot):\n",
    "    gs_comb = gs_snapshot.merge(price_cal, on =['store_id','item_id','snapshot_date'],how = 'left')\n",
    "    return gs_comb\n",
    "\n",
    "def extract_id_info(id1):\n",
    "    id_info= id1.split('_')\n",
    "    state = id_info[3]\n",
    "    category = id_info[0]\n",
    "    return state,category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_snaps(gs_comb,id1):\n",
    "    state, category = extract_id_info(id1)\n",
    "    snap_days_CA = gs_comb[gs_comb['snap_CA']==1]['snapshot_date'].unique()\n",
    "    snap_days_TX = gs_comb[gs_comb['snap_TX']==1]['snapshot_date'].unique()\n",
    "    snap_days_WI = gs_comb[gs_comb['snap_TX']==1]['snapshot_date'].unique()\n",
    "    if state =='CA':\n",
    "        return snap_days_CA\n",
    "    elif state == 'TX':\n",
    "        return snap_days_TX\n",
    "    else:\n",
    "        return snap_days_WI\n",
    "\n",
    "\n",
    "def get_train_val_dates(split,gs_comb):\n",
    "    gs_comb['snapshot_date'] = gs_comb['snapshot_date'].apply(lambda x:datetime.datetime.strptime(x,'%Y-%m-%d').date())\n",
    "    start_day = datetime.datetime.strptime('2011-01-29','%Y-%m-%d').date()\n",
    "    dates = [start_day + i*datetime.timedelta(days =1) for i in range(0,len(d_cols))]\n",
    "    train_start = 0\n",
    "    train_start = dates[0]\n",
    "    train_end = dates[int(split*len(dates))]\n",
    "    return train_start,train_end\n",
    "    #train_end_ind = 0.9*len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_holidays(gs_comb,id1):\n",
    "    Hol1_rel = gs_comb[gs_comb['event_type_1']=='Religious']['snapshot_date'].unique()\n",
    "    Hol1_nat = gs_comb[gs_comb['event_type_1']=='National']['snapshot_date'].unique()\n",
    "    Hol1_cul = gs_comb[gs_comb['event_type_1']=='Cultural']['snapshot_date'].unique()\n",
    "    Hol1_Sp = gs_comb[gs_comb['event_type_1']=='Sporting']['snapshot_date'].unique()\n",
    "\n",
    "    #----------------------------\n",
    "    Hol2_rel = gs_comb[gs_comb['event_type_2']=='Religious']['snapshot_date'].unique()\n",
    "    Hol2_cul = gs_comb[gs_comb['event_type_2']=='Cultural']['snapshot_date'].unique()\n",
    "    \n",
    "    #train_start, train_end = get_train_val_dates(split, gs_comb)\n",
    "    snap_days1 = pd.DataFrame({\n",
    "      'holiday': 'snaps',\n",
    "      'ds': pd.to_datetime(select_snaps(gs_comb, id1)),\n",
    "      'lower_window': 0,\n",
    "      'upper_window': 0,\n",
    "    })\n",
    "\n",
    "    holiday1_rel = pd.DataFrame({\n",
    "      'holiday': 'holiday_religious',\n",
    "      'ds': pd.to_datetime(Hol1_rel),\n",
    "      'lower_window': -1,\n",
    "      'upper_window': 1,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "    holiday1_cul = pd.DataFrame({\n",
    "      'holiday': 'holiday_cultural',\n",
    "      'ds': pd.to_datetime(Hol1_cul),\n",
    "      'lower_window': -1,\n",
    "      'upper_window': 1,\n",
    "    })\n",
    "\n",
    "    holiday1_nat = pd.DataFrame({\n",
    "      'holiday': 'holiday_national',\n",
    "      'ds': pd.to_datetime(Hol1_nat),\n",
    "      'lower_window': -1,\n",
    "      'upper_window': 1,\n",
    "    })\n",
    "\n",
    "\n",
    "    holiday2_cul = pd.DataFrame({\n",
    "      'holiday': 'holiday_religious',\n",
    "      'ds': pd.to_datetime(Hol2_cul),\n",
    "      'lower_window': -1,\n",
    "      'upper_window': 1,\n",
    "    })\n",
    "\n",
    "\n",
    "    holiday2_rel = pd.DataFrame({\n",
    "      'holiday': 'holiday_religious',\n",
    "      'ds': pd.to_datetime(Hol2_rel),\n",
    "      'lower_window': -1,\n",
    "      'upper_window': 1,\n",
    "    })\n",
    "    holidays = pd.concat((snap_days1,holiday1_rel,holiday1_cul,holiday1_nat,holiday2_cul,holiday2_rel ))\n",
    "    return holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(gs_comb,holidays, id1, train_end):\n",
    "    data = gs_comb[gs_comb['id']==id1]\n",
    "    data2 = data.rename({'snapshot_date':'ds','sales':'y'},axis=1)[['sell_price','ds','y']]\n",
    "    data2_tr = data2[data2['ds']<=train_end]\n",
    "    median =  data2_tr['sell_price'].median(axis = 0)\n",
    "    data2_tr['sell_price'] = data2_tr['sell_price'].fillna(median)\n",
    "    data2_tr['ds'] = data2_tr['ds'].astype('datetime64')\n",
    "    m2 = Prophet(holidays=holidays,weekly_seasonality = True, yearly_seasonality= True,changepoint_prior_scale = 0.7,uncertainty_samples = True)\n",
    "    m2.add_seasonality(name='monthoy', period=30.5, fourier_order=5)\n",
    "    m2.add_regressor('sell_price')\n",
    "    m2.fit(data2_tr)\n",
    "    return m2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(m2,gs_comb,id1,train_end):\n",
    "      data = gs_comb[gs_comb['id']==id1]\n",
    "      data2 = data.rename({'snapshot_date':'ds','sales':'y'},axis=1)[['sell_price','ds','y']]\n",
    "      data2_tr = data2[data2['ds']<=train_end]\n",
    "      data2_val = data2[data2['ds']>train_end]\n",
    "      n_days_val = data2_val.shape[0]\n",
    "      future = m2.make_future_dataframe(periods = n_days_val)\n",
    "      future['sell_price'] = np.array(data['sell_price'])\n",
    "      median = data[data['snapshot_date']>train_end]['sell_price'].median(axis =0)\n",
    "      future['sell_price'] = future['sell_price'].fillna(median)\n",
    "      forecast2 = m2.predict(future)\n",
    "      return forecast2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_validation_file(forecast2,id1):\n",
    "    item_id = id1\n",
    "    F_cols = np.array(['F'+str(i) for i in range(1,29)])\n",
    "    submission = pd.DataFrame(columns=F_cols)\n",
    "    submission.insert(0,'id',item_id)\n",
    "    forecast2['yhat'] = np.where(forecast2['yhat']<0,0,forecast2['yhat'])\n",
    "    forecast2.rename({'yhat':'y','ds':'ds'},inplace=True,axis = 1)\n",
    "    forecast2_T = forecast2[['ds','y']].T\n",
    "    submission.loc[1,'id'] =item_id\n",
    "    submission[F_cols] = forecast2_T.loc['y',:].values[-28:]\n",
    "    submission.head()\n",
    "    col_order = np.insert(F_cols,0,'id')\n",
    "    sub_val = submission[col_order]\n",
    "    #sub_val.to_csv('submission.csv',index = False)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs_comb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-853f724734e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_holidays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_comb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gs_comb' is not defined"
     ]
    }
   ],
   "source": [
    "get_holidays(gs_comb,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_prophet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b68138fd1b50>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mforecast1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_prophet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtemp_series\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'run_prophet' is not defined"
     ]
    }
   ],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "        forecast1 = p.map(run_prophet, [temp_series])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1():\n",
    "    id_lst = sales_data['id'].unique().tolist()\n",
    "    train_end = split_train_val() \n",
    "    gs_snapshot = create_snapshot(calendar_data, sales_data)\n",
    "    price_cal = merge_price_cal_data(price_data,calendar_data)\n",
    "    gs_comb = merge_snapshot_pricecal(price_cal,gs_snapshot)\n",
    "    state,category = extract_id_info(id_lst[5])\n",
    "    print(state)\n",
    "    #a1 = get_snap_days(gs_comb,5)\n",
    "    hols = get_holidays(gs_comb,id_lst[5])\n",
    "    model = train_model(gs_comb,hols,id_lst[5],train_end)\n",
    "    forecast2 = make_prediction(model,gs_comb, id_lst[5],train_end)\n",
    "    submission = make_validation_file(forecast2,id_lst[5])\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prophet(gs_comb,id1):\n",
    "    state,category = extract_id_info(id1)\n",
    "    hols = get_holidays(gs_comb,id1)\n",
    "    model = train_model(gs_comb,hols,id1,train_end)\n",
    "    forecast2 = make_prediction(model,gs_comb, id1,train_end)\n",
    "    submission = make_validation_file(forecast2,id1)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
